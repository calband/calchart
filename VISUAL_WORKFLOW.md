# CalChart Performance Optimization - Visual Workflow

## Decision Tree

```
                        START: Sanity tests are slow
                               /
                              /
                    Phase 1: Instrument Code
                    (Add timing measurements)
                             |
                             â†“
                    Run: python3 resources/tests/sanity_tester.py
                             |
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â†“                     â†“
        Look at metrics output   Look for breakdown:
        
        Command execution: X.XXs (YY.Y%)
        File comparison:   X.XXs (YY.Y%)
        Overhead (I/O):    X.XXs (YY.Y%)
        
                  |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“         â†“         â†“
    
    80%+?     20%+?     15%+?
    Exec      Comp      Overhead
    
        â†“         â†“         â†“
    Phase 3A   Phase 3B   Phase 3C
    Multi-     Optimize   Optimize
    thread     Regex      Harness
    cmd                   
    
        â†“         â†“         â†“
    
  Implement  Implement  Implement
  C++ code   Python     Python
  changes    changes    changes
  
        â†“         â†“         â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
        Re-run instrumented tests
        Compare before/after metrics
                  â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                        â†“
    Speedup                  Still slow?
    achieved?          Try next Phase 3
    
    YESâ†“                    optionâ†“
    âœ“ SUCCESS             Loop back &
    Done!                 measure
```

---

## Time Distribution (Current State - Unknown)

We need to measure this with Phase 1:

```
Total sanity_tester runtime: ~45s (example)

Current state (unknown distribution):
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 45s

Scenarios after Phase 1:

Scenario A (80% exec):
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ â–ˆ 45s
Command Execution (36s)
File Comparison (2s)
Overhead (7s)
â†’ Focus: Phase 3A (Multi-thread calchart_cmd)

Scenario B (20% comparison):
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆ 45s
Command Execution (32s)
File Comparison (9s)
Overhead (4s)
â†’ Focus: Phase 3B (Optimize regex)

Scenario C (15% overhead):
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆ 45s
Command Execution (32s)
File Comparison (7s)
Overhead (6s)
â†’ Focus: Phase 3C (Optimize harness)
```

---

## Phase 3A: Multi-thread calchart_cmd

```
Current (Sequential):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ calchart   â”‚  Sheet 1  â† 4s
â”‚ _cmd       â”‚  Sheet 2  â† 4s
â”‚ _cmd       â”‚  Sheet 3  â† 4s
â”‚ (process)  â”‚  Sheet 4  â† 4s
â”‚            â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚            â”‚  Total: 16s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Threading (Parallel):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ calchart_cmd (process) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Thread Pool (4)    â”‚â”‚
â”‚  â”‚ â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚ â”‚S1â”‚S2â”‚S3â”‚ wait â”‚â”‚
â”‚  â”‚ â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Total: 4s             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Speedup: 4x (with 4 cores)
```

**Key implementation points**:
- Add thread pool to calchart_cmd
- Parallelize sheet processing
- Potentially parallelize output format generation

---

## Phase 3B: Optimize Regex

```
Current (Naive):
for each line:
    result = subprocess.run(complex_regex)  â† 1000x per file
    compare result

Optimized:
compiled_regex = re.compile(pattern)       â† Once at start

for each line:
    if line.startswith("pt "):             â† Fast check first
        value = compiled_regex.match(line)  â† Reuse compiled regex
        compare value
    else:
        direct_string_compare(line)         â† Skip regex for others

Speedup: 2-3x in comparison phase
```

---

## Phase 3C: Optimize Harness

```
Current (Manual Process Management):
processes = []
for file in all_files:
    for variant in 10_variants:
        process = Process(...)
        process.start()
        processes.append(process)
        
        if len(processes) >= num_cores:
            join_all()

Optimized (ProcessPoolExecutor):
with ProcessPoolExecutor(max_workers=num_cores) as executor:
    futures = []
    for file in all_files:
        for variant in 10_variants:
            future = executor.submit(run_command, ...)
            futures.append(future)
    
    wait_all(futures)

Benefits:
- Automatic worker reuse (no per-process startup)
- Better load balancing
- Cleaner code
```

---

## Before & After Timeline

```
Before (Debug Mode):
Build:  5s  â”
Test:  60s  â”œâ”€â†’ Total: ~70s per iteration (slow!)
           â”˜

After optimization (assumed 2.5x speedup):
Build:  5s  â”
Test:  24s  â”œâ”€â†’ Total: ~30s per iteration (fast!)
           â”˜

Time saved per 10-iteration dev session: ~400s = 6-7 minutes! ğŸ‘
```

---

## Code Change Summary

```
Phase 1: sanity_tester.py modifications
â”œâ”€â”€ Add imports (time, json, dataclasses)
â”œâ”€â”€ Add metrics data structures (CommandMetrics, ComparisonMetrics, etc.)
â”œâ”€â”€ Add TimedBlock context manager
â”œâ”€â”€ Wrap subprocess.run() calls with timing
â”œâ”€â”€ Wrap compare_files() with metrics collection
â”œâ”€â”€ Add report generation function
â””â”€â”€ Modify main() to aggregate & print metrics

Lines of code: ~200-300 lines of instrumentation code

Phase 3A: calchart_cmd modifications (IF NEEDED)
â”œâ”€â”€ tools/calchart_cmd/main.cpp
â”œâ”€â”€ tools/calchart_cmd/calchart_cmd_parse.hpp
â””â”€â”€ Potentially src/core/* files for parallelization

Lines of code: ~100-200 lines of C++ threading code

Phase 3B: sanity_tester.py regex optimizations (IF NEEDED)
â”œâ”€â”€ Compile regex at module level
â”œâ”€â”€ Optimize extractValues() with pre-compiled regex
â””â”€â”€ Add fast-path checks

Lines of code: ~20-30 lines

Phase 3C: sanity_tester.py harness optimization (IF NEEDED)
â”œâ”€â”€ Replace manual Process with ProcessPoolExecutor
â””â”€â”€ Simplify process management

Lines of code: ~20-50 lines
```

---

## Testing Strategy

```
Step 1: Baseline (Before Optimization)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Run: python3 resources/tests/       â”‚
â”‚      sanity_tester.py -d shows      â”‚
â”‚      -c ./build/tools/calchart_cmd/ â”‚
â”‚      calchart_cmd                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Review metrics output
   Note: total time, phase breakdown
   Example: 45.67s total
        â†“
   Save output (metrics.json created)


Step 2: Implement Phase 3X
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edit code based on Phase 3 choice    â”‚
â”‚ Rebuild: cmake --build build         â”‚
â”‚ Run tests to verify no regressions   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“


Step 3: Post-Optimization
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Run: python3 resources/tests/       â”‚
â”‚      sanity_tester.py -d shows      â”‚
â”‚      -c ./build/tools/calchart_cmd/ â”‚
â”‚      calchart_cmd                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Review metrics output
   Compare: 45.67s â†’ 22.3s? (2.05x)
        â†“
   Success! Or run Phase 3Y if needed


Step 4: Repeat if Necessary
If still too slow:
        â†“
   Identify next bottleneck
   Implement Phase 3Y
   Re-measure
```

---

## Expected Outcomes by Scenario

```
If Phase 1 shows: exec=88%, comp=7%, overhead=5%
â†’ Phase 3A: Multi-thread calchart_cmd
â†’ Expected: 45s â†’ 20s (2.25x) âœ“ Meets goal!

If Phase 1 shows: exec=60%, comp=25%, overhead=15%
â†’ Phase 3B: Optimize regex (improves 25% to 8%)
â†’ Result: 45s â†’ 30s (1.5x)
â†’ If needed, also do Phase 3A or 3C

If Phase 1 shows: exec=65%, comp=10%, overhead=25%
â†’ Phase 3C: Optimize harness (reduces overhead)
â†’ Result: 45s â†’ 35s (1.3x)
â†’ Likely also need Phase 3A
```

---

## Success Criteria Checklist

```
Before:          Phase 1      Phase 3X      Final
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Slow (60s)   â†’  Measured   â†’  Optimized  â†’  FAST (20-30s)
                (where?)       (how much?)
                
Tests pass âœ“     âœ“            âœ“ (verify!)     âœ“
Metrics         Visible in     (repeat        Still visible
              console & JSON   Phase 1)       in output
                
                              Speedup: 2-3x âœ“
```

---

## Development Commit Pattern

```
Commit 1: "Add performance instrumentation to sanity_tester"
â”€ Phase 1 implementation
â”€ Shows timing and metrics output

Commit 2: "Phase 3X: [Optimization description]"
â”€ Specific Phase 3A/3B/3C changes
â”€ References metrics showing X% speedup

Commit 3 (if needed): "Phase 3Y: [Additional optimization]"
â”€ If multiple phases needed

Branch: feature/sanity-tester-performance
PR description: 
  - Before: X seconds
  - After: Y seconds (Z% speedup)
  - Metrics output showing breakdown
```

---

## Resources

- [QUICK_REFERENCE.md](QUICK_REFERENCE.md) â€” TL;DR guide
- [PERFORMANCE_IMPROVEMENT_PLAN.md](PERFORMANCE_IMPROVEMENT_PLAN.md) â€” Full strategy
- [PHASE_1_IMPLEMENTATION.md](PHASE_1_IMPLEMENTATION.md) â€” Step-by-step code changes
- [PERFORMANCE_OPTIMIZATION_SUMMARY.md](PERFORMANCE_OPTIMIZATION_SUMMARY.md) â€” Executive summary

Start here: [QUICK_REFERENCE.md](QUICK_REFERENCE.md)

